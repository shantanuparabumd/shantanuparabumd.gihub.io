{
  "projects": [
    {
      "id": 1,
      "title": "Drone Delivery Simulation",
      "image": "images/project/drone.webp",
      "description": "A drone simulation system for automated parcel delivery with Gazebo and ROS plugins.",
      "tags": ["Gazebo", "ROS", "Blender", "SolidWorks", "Drone Simulation"],
      "github": "https://github.com/shantanuparabumd/drone_delivery",
      "video": "images/videos/drone.mp4",
      "date": "May 2024",
      "longDescription": "This project involves developing a simulated drone delivery system using Gazebo, ROS, SolidWorks, and Blender. The drone, modeled in SolidWorks, is equipped with custom plugins for flight control, odometry publishing, and vacuum gripper functionality for picking up and placing parcels based on detected Aruco markers. The drone's flight is stabilized through a PID controller, while odometry data serves as feedback. The environment and parcels are modeled in Blender, with necessary physics adjustments for realistic simulation. The article provides a step-by-step guide on developing plugins for drone flight, grasping, and controlled delivery of parcels in specified locations.",
      "media": [
        {
          "type": "image",
          "url": "images/project/drone.webp"
        },
        {
          "type": "video",
          "url": "images/videos/drne.mp4"
        },
        {
          "type": "article",
          "image": "images/project/drone.webp",
          "url": "https://medium.com/@shantanuparab99/unleashing-the-power-of-simulation-engines-writing-plugins-for-enhanced-drone-simulations-ab7c847ca432"
        }
      ]
    },

    {
      "id": 2,
      "title": "Quadruped Robot Simulation",
      "image": "images/project/quadruped.png",
      "description": "A Quadruped Robot designed from scratch in SolidWorks and simulated in Gazebo with ROS communication and Python control.",
      "tags": ["ROS", "Gazebo", "SolidWorks", "Inverse Kinematics", "URDF", "Python"],
      "github": "https://github.com/shantanuparabumd/quad_robo",
      "video": "",
      "date": "November 2023",
      "longDescription": "In this project, I designed a Quadruped Robot from the ground up using SolidWorks, converted it to URDF for ROS integration, and simulated it in Gazebo. Key highlights include the detailed design in SolidWorks, URDF conversion for seamless ROS integration, implementation of inverse kinematics using DH parameters and Jacobian methods, and robust ROS communication for controlling the robot’s movements. Additionally, I developed a Python script for interactive control of the robot, making it versatile and user-friendly in the simulation environment. This project showcases my skills in Robot Modelling, Simulation, and ROS, providing valuable experience with Gazebo and Python control systems.",
      "media": [
        {
          "type": "video",
          "url": "images/videos/quadruped.mp4"
        },
        {
          "type": "article",
          "image": "images/project/quadruped.png",
          "url": "https://www.linkedin.com/posts/shantanu-parab_robotics-simulation-rosnoetic-activity-7093805585623572481-FQK-?utm_source=share&utm_medium=member_desktop"
        }
      ]
    },

    {
      "id": 3,
      "title": "Autonomous Robot",
      "image": "images/project/autobot.png",
      "description": "Developed an autonomous vehicle capable of navigating complex obstacle courses and performing object manipulation tasks.",
      "tags": ["ROS2", "C++", "Python", "Perception", "Path Planning", "Raspberry Pi", "YOLO", "MiDAS"],
      "github": "https://github.com/shantanuparabumd/Autonomous-Robot-809T",
      "video": "",
      "date": "May 2023",
      "longDescription": "This project involved designing and constructing an autonomous vehicle that navigates complex environments and performs object manipulation. Using a Raspberry Pi with Ubuntu 20.04 and ROS2 Galactic, the vehicle integrates various sensors and advanced algorithms. Object detection is handled by YOLO, allowing efficient identification of colored objects, while MiDAS provides depth estimation for accurate perception. Localization is achieved through encoders and IMU sensors, with the RRT* algorithm for global path planning and a potential field algorithm for dynamic path planning, ensuring real-time adaptation to moving obstacles. Custom libraries were developed to enable seamless communication between hardware components via UART, SPI, and I2C protocols, resulting in a robust system capable of autonomous navigation and manipulation in dynamic settings.",
      "media": [
        {
          "type": "image",
          "url": "images/project/autobot.png"
        },
        {
          "type": "video",
          "url": "images/videos/autorobot.mp4"
        },
        {
          "type": "video",
          "url": "images/videos/grandchallenge.mp4"
        }
      ]
    },

    {
      "id": 4,
      "title": "ARIAC Project",
      "image": "images/project/ariac.png",
      "description": "Implemented robotics solutions for industrial automation tasks as part of the ARIAC competition.",
      "tags": ["ROS", "Industrial Automation", "Robotics", "Automation"],
      "github": "https://github.com/shantanuparabumd/ariac_2024",
      "video": "",
      "date": "May 2024",
      "longDescription": "As part of the Agile Robotics for Industrial Automation Competition (ARIAC), I developed robotics solutions focused on enhancing industrial automation processes. My work involved creating automated systems to manage complex tasks efficiently, using ROS for modular and scalable development. This project emphasized real-world applications in industrial environments, challenging me to optimize robotic actions for high precision and reliability, which are critical in automation workflows.",
      "media": [
        {
          "type": "image",
          "url": "images/project/ariac.png"
        },
        {
          "type": "video",
          "url": "images/videos/ARIAC.mp4"
        },
        {
          "type": "video",
          "url": "images/videos/ariac.mp4"
        }
      ]
    },

    {
      "id": 5,
      "title": "Autonomous Vehicle Simulation",
      "image": "images/project/autovehicle.png",
      "description": "Developed a ROS2-based autonomous vehicle simulation using Gazebo, equipped with advanced path planning and obstacle avoidance capabilities.",
      "tags": ["ROS2", "Gazebo", "Path Planning", "C++", "Python", "LiDAR", "Computer Vision"],
      "github": "https://github.com/shantanuparabumd/autonomous_vehicle",
      "video": "",
      "date": "March 2024",
      "longDescription": "This project involved developing an autonomous vehicle simulation using a Toyota Prius model in the Gazebo environment, with ROS2 integration for sensor and actuator control. Using sensor fusion from LiDAR and camera data, the simulation enabled accurate obstacle detection and lane recognition. I implemented the RRT* algorithm for efficient global path planning, allowing the vehicle to navigate through static obstacles. For dynamic obstacles, I utilized potential field algorithms to facilitate real-time path adjustments. OpenCV was employed for lane and obstacle identification, enhancing the vehicle's navigation capabilities. In line with Agile practices, this project involved rigorous testing with the Google Test Suite and continuous integration to ensure code robustness.",
      "media": [
        {
          "type": "image",
          "url": "images/project/autovehicle.png"
        },
        {
          "type": "video",
          "url": "images/videos/auto_vehicle.mp4"
        },
        {
          "type": "article",
          "image": "images/project/autovehicle.png",
          "url": "https://www.linkedin.com/posts/shantanu-parab_osrf-autonomousvehicles-ros2-activity-7183615111591325696-FY1u?utm_source=share&utm_medium=member_desktop"
        }
      ]
    },

    {
      "id": 6,
      "title": "Point Cloud Classification",
      "image": "images/project/pred_sample_1 (1).gif",
      "description": "Explored advanced 3D vision techniques for point cloud classification using PointNet and 3D model generation using NeRF.",
      "tags": ["Python", "PointNet", "3D Vision", "Computer Vision"],
      "github": "https://github.com/shantanuparabumd/assignment4_sparab",
      "video": "",
      "date": "December 2023",
      "longDescription": "This project implements PointNet for 3D object classification and segmentation tasks using point cloud data. The classification model achieves a high test accuracy of 97.9%, while the segmentation model achieves 90.26% accuracy, both trained over 250 epochs. Robustness analysis reveals that reducing the number of points degrades performance due to loss of critical features, while extreme rotations cause misclassifications due to unseen orientations during training. Quantitative and qualitative results highlight the models' strengths in capturing object geometries, with noted challenges in distinguishing similar shapes like lamps and vases or handling densely packed components in segmentation tasks.",
      "media": [
        {
          "type": "image",
          "url": "images/project/classification_515_gt_chair_pred_chair.gif"
        },
        {
          "type": "image",
          "url": "images/project/classification_631_gt_vase_pred_vase.gif"
        },
        {
          "type": "image",
          "url": "images/project/classification_673_gt_vase_pred_lamp.gif"
        },
        {
          "type": "image",
          "url": "images/project/pred_sample_1.gif"
        },
        {
          "type": "image",
          "url": "images/project/pred_sample_2.gif"
        }
      ]
    },    

    {
      "id": 7,
      "title": "Swarm Robotics: Firefly Algorithm",
      "image": "images/project/firefly.png",
      "description": "Implemented a bio-inspired Firefly algorithm for swarm robotics in a Gazebo simulation using ROS2, enabling object identification and collaborative decision-making.",
      "tags": ["ROS2", "C++", "OpenCV", "Firefly Algorithm"],
      "github": "https://github.com/shantanuparabumd/firefly_swarm",
      "video": "",
      "date": "October 2023",
      "longDescription": "This project explores swarm robotics through a bio-inspired decision-making algorithm based on the Firefly Algorithm, implemented within the Gazebo simulation environment using ROS2. Using Turtle robots with camera sensors and IMUs, the system identifies colored objects and builds a global map, demonstrating intelligent collective behavior. Each robot locates objects with OpenCV and uses the Firefly algorithm to simulate attraction based on intensity and distance, causing robots to cluster near objects of interest. This approach illustrates the application of swarm intelligence in tasks such as search and rescue, where robots gather and navigate collaboratively. The project successfully showcases the Firefly algorithm's potential for swarm-based decision-making and object localization in simulated environments, expanding its use beyond traditional optimization problems.",
      "media": [
        {
          "type": "video",
          "url": "images/videos/firefly.mp4"
        },
        {
          "type": "article",
          "image": "images/project/firefly.png",
          "url": "https://medium.com/@shantanuparab99/firefly-algorithm-bio-inspired-decision-making-algorithm-d25941725d14"
        }
      ]
    },

    {
      "id": 8,
      "title": "Conveyor Belt Plugin for Gazebo",
      "image": "images/project/conveyor.png",
      "description": "Developed a custom Gazebo plugin to simulate a conveyor belt, complete with object motion control using ROS2.",
      "tags": ["ROS2", "Gazebo", "C++", "Simulation", "Custom Plugin"],
      "github": "https://github.com/shantanuparabumd/conveyor_belt",
      "video": "",
      "date": "September 2023",
      "longDescription": "In this project, I created a conveyor belt simulation within the Gazebo environment, utilizing a custom ROS2 plugin for precise object movement. Inspired by the ARIAC competition, this setup features a URDF model of a conveyor belt controlled via a prismatic joint, enabling continuous forward motion. To ensure objects move forward without returning with the belt, the plugin resets the belt's position at each cycle, allowing objects to progress independently along the belt. The project includes launch scripts and a 'spawn_object' script, making the conveyor belt easily deployable in diverse simulation scenarios. This project illustrates how to create custom Gazebo plugins, enhancing simulation capabilities and providing insights into real-world industrial scenarios.",
      "media": [
        {
          "type": "video",
          "url": "images/videos/conveyor.mp4"
        },
        {
          "type": "article",
          "image": "images/blogs/conveyor.png",
          "url": "https://www.linkedin.com/pulse/gazebo-custom-plugin-ros2-step-by-step-guide-shantanu-parab/"
        },
        {
          "type": "article",
          "image": "images/blogs/contruct.jpeg",
          "url": "https://www.linkedin.com/feed/update/urn:li:activity:7210220325630877696/"
        }
      ]
    },

    {
      "id": 9,
      "title": "Path Planning for Non-Holonomic Robots",
      "image": "images/project/path.png",
      "description": "Implemented Dubins curves and A* search algorithms in Python, tested with weighted A* and Dijkstra's, and validated using a ROS1 node on a TurtleBot3 in Gazebo.",
      "tags": ["ROS2", "Gazebo", "C++", "Simulation", "Path Planning"],
      "github": "https://github.com/VKSingh03/astar_turtlebot_ros_noetic",
      "video": "",
      "date": "March 2023",
      "longDescription": "Developed a motion planning system for a robot simulating car-like forward motion using the concept of Dubins curves to generate feasible action sets for trajectory simulation. Implemented the A* search algorithm from scratch in Python to find optimal paths, along with comparative studies of weighted A* and Dijkstra's algorithms to evaluate their performance and efficiency. The solution was integrated into a ROS1 framework, where a custom ROS node was developed to simulate and test the algorithms on a TurtleBot3 within a Gazebo environment, ensuring realistic evaluation of motion planning and pathfinding strategies.",
      "media": [
        {
          "type": "video",
          "url": "images/videos/turtlebot_pp.mp4"
        },
        {
          "type": "video",
          "url": "images/videos/turtlebot_pp2.mp4"
        }
      ]
    },

    {
      "id": 10,
      "title": "Advancing Esports Analytics using CNN and LSTM",
      "image": "images/project/valorant.jpg",
      "description": "Designed a CNN + LSTM Neural network to do live win prediction for the Valorant video game.",
      "tags": ["Pytorch", "Computer Vision", "CNN", "LSTM"],
      "github": "https://github.com/VKSingh03/astar_turtlebot_ros_noetic",
      "video": "",
      "date": "December 2023",
      "longDescription": "Developed a deep learning framework for predicting match outcomes in the game Valorant by leveraging a combination of Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM) networks. The CNNs were utilized to extract and analyze critical in-game visual elements, while the LSTMs captured and interpreted temporal patterns essential for understanding the flow of the game. As no pre-existing dataset matched the project requirements, a custom dataset was meticulously created from competition videos, ensuring a rich and diverse data source. The model was rigorously trained and tested, achieving a prediction accuracy that surpassed previously attainable benchmarks, demonstrating the effectiveness of the integrated CNN-LSTM approach in capturing both spatial and temporal dynamics of the game. This project was conducted as part of a course to explore the intersection of deep learning and e-sports analytics.",
      "media": [
        {
          "type": "video",
          "url": "images/videos/esport.mp4"
        },
        {
          "type": "article",
          "image": "images/project/valorant.jpg",
          "url": "images/reports/enmp809k_project_report.pdf"
        }
        
      ]
    },

    {
      "id": 11,
      "title": "Neural Implicit Representation based SLAM techniques",
      "image": "images/project/nerf.png",
      "description": "Explored and benchmarked state-of-the-art Neural Radiance Field (NeRF) methods for generating high-fidelity 3D models, emphasizing their practical applications and performance trade-offs.",
      "tags": ["Pytorch", "Computer Vision", "CNN", "LSTM"],
      "github": "https://github.com/VKSingh03/astar_turtlebot_ros_noetic",
      "video": "",
      "date": "December 2023",
      "longDescription": "The NeRF Comparative Study project focused on evaluating and benchmarking advanced Neural Radiance Field (NeRF) techniques for generating detailed 3D models from 2D image datasets. This research aimed to understand the practical applications, strengths, and limitations of NeRF methods in diverse real-world scenarios. The study involved implementing various NeRF architectures to reconstruct complex objects, such as a Lego bulldozer, and comparing their performance in terms of rendering quality, computational efficiency, and adaptability to different datasets. The analysis included varying training parameters, such as the number of epochs, to optimize results and identify the trade-offs between computational cost and model fidelity. Through this project, valuable insights were gained into how NeRF techniques can transform 3D vision tasks, such as digital twin creation, virtual reality, and robotics. The outcomes highlight the potential of NeRF methods to set new benchmarks in 3D model generation while addressing key challenges like dataset requirements and computational constraints.",
      "media": [
        {
          "type": "article",
          "image": "images/project/nerf.png",
          "url": "images/reports/cmsc848f_project_report.pdf"
        }
      ]
    },

    {
      "id": 12,
      "title": "Single View Image to 3D",
      "image": "images/project/mesh_render.gif",
      "description": "Developed a pipeline to reconstruct 3D objects from single-view images using voxel grids, point clouds, and meshes, employing custom decoders, hyperparameter tuning, and iterative visualizations for enhanced understanding and performance.",
      "tags": ["Pytorch", "Computer Vision", "3D Vision"],
      "github": "https://github.com/shantanuparabumd/assignment_2_sparab",
      "video": "",
      "date": "October 2023",
      "longDescription": "This project reconstructs 3D objects from single-view images using voxel grids, point clouds, and meshes. Loss functions like Binary Cross Entropy, Chamfer Loss, and smoothness loss ensure accurate fitting. By tuning hyperparameters such as batch size and increasing training workers, the pipeline achieves improved convergence and efficient performance. Visualizations across iterations showcase how reconstructions evolve from uniform shapes to detailed 3D models. Quantitative evaluations highlight point cloud and mesh methods as superior in capturing fine details compared to voxels, which face memory constraints. The study emphasizes iterative visualization and optimized training for effective 3D reconstruction.",
      "media": [
        {
          "type": "image",
          "url": "images/project/voxel_render.gif"
        },
        {
          "type": "image",
          "url": "images/project/point_render.gif"
        },
        {
          "type": "image",
          "url": "images/project/mesh_gt_batch16_instance2.gif"
        },
        {
          "type": "image",
          "url": "images/project/mesh_gt_batch16_instance8.gif"
        },
        {
          "type": "image",
          "url": "images/project/mesh_gt_batch16_instance8 (1).gif"
        }
      ]
    },

    {
      "id": 12,
      "title": "NeRF Rendering",
      "image": "images/project/lego.gif",
      "description": "Implemented a pipeline for Neural Radiance Fields (NeRF) using differentiable volume rendering, ray sampling, and optimization techniques to generate 3D scene representations and realistic renderings.",
      "tags": ["Pytorch", "Computer Vision", "CNN", "LSTM"],
      "github": "https://github.com/shantanuparabumd/assignment3_sparab",
      "video": "",
      "date": "November 2023",
      "longDescription": "This project implements a Neural Radiance Field (NeRF) pipeline using differentiable volume rendering to create realistic 3D scene representations. It includes ray sampling to map pixels to world-space rays, point sampling to stratify along rays, and volume rendering to aggregate weights and compute depth maps. The pipeline optimizes a 3D implicit volume to reconstruct a box with known ground truth images and trains a neural radiance field for realistic scene renderings. Progressive visualizations highlight improvements over epochs, showcasing depth maps, point clouds, and final rendered images. The project leverages PyTorch3D and references advanced resources for a robust exploration of neural 3D modeling.",
      "media": [
        {
          "type": "image",
          "url": "images/project/lego.gif"
        }
      ]
    },

    {
      "id": 13,
      "title": "TD3 Reinforcement Learning for Quadruped Locomotion",
      "image": "images/project/evaluation_demo_loop.gif",
      "description": "Developed a robust RL pipeline using the TD3 algorithm to train a simulated quadruped (Ant) for efficient and stable locomotion in the Gymnasium Ant-v5 environment.",
      "tags": ["Reinforcement Learning", "TD3", "Gymnasium", "PyTorch"],
      "github": "https://github.com/shantanuparabumd/openai_gym",
      "video": "",
      "date": "November 2023",
      "longDescription": "This project applies the Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm to train a simulated quadruped robot in the Gymnasium Ant-v5 environment. The TD3 algorithm, known for its robustness in continuous action spaces, leverages features such as target policy smoothing, clipped double Q-learning, and delayed updates to stabilize training and reduce overestimation bias. Custom reward functions incentivize forward velocity, stable torso posture, and efficient gait patterns. \n\nTraining visualizations include progress plots, contact force analyses, and gait trajectories, showcasing the agent’s development of a stable and dynamic trot gait. YAML-based configuration files manage training parameters, reward structures, and environment settings, providing flexibility and modularity. This project serves as an in-depth exploration of reinforcement learning for robotics, offering insights into gait optimization and continuous control tasks.",
      "media": [
        {
          "type": "video",
          "url": "images/project/evaluation_demo.mp4"
        },
        {
          "type": "image",
          "url": "images/project/evaluation_demo_loop.gif"
        }
      ]
    }
    
    

      

      
  ]
}
